{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Q5.ipynb","provenance":[],"collapsed_sections":[],"mount_file_id":"1tyYIcYbauJFoeBBVZu8U9gNCT-lAHJ-n","authorship_tag":"ABX9TyNC4iYIC2QrPHul8YVfabxb"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","metadata":{"id":"oNX4VkDZWhtU","executionInfo":{"status":"ok","timestamp":1632314731775,"user_tz":-330,"elapsed":333,"user":{"displayName":"Abhay Patwari","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gix32BX_ssvRlYOdFlU8riZsgPg3lrL-_h0Lvui=s64","userId":"16538957145694214892"}}},"source":["import numpy as np\n","import pandas as pd\n","\n","def h(x,w):\n","  return 1/(1 + np.exp(-1*np.dot(x,w)))\n","\n","def conf_matrix(y,pred):\n","  m = np.zeros(4)\n","  for i in range(len(y)):\n","    if y[i]==0 and pred[i]==0:\n","      m[0] += 1\n","    if y[i]==0 and pred[i]==1:\n","      m[1] += 1\n","    if y[i]==1 and pred[i]==0:\n","      m[2] += 1\n","    if y[i]==1 and pred[i]==1:\n","      m[3] += 1\n","  return m"],"execution_count":56,"outputs":[]},{"cell_type":"code","metadata":{"id":"SzDNZMtAaz_Y","executionInfo":{"status":"ok","timestamp":1632314736229,"user_tz":-330,"elapsed":3,"user":{"displayName":"Abhay Patwari","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gix32BX_ssvRlYOdFlU8riZsgPg3lrL-_h0Lvui=s64","userId":"16538957145694214892"}}},"source":["data = pd.read_excel(\"/content/drive/MyDrive/NNFL Assignments (Aug 2021)/Assignment 1/data_q4_q5.xlsx\")\n","data = data.sample(frac=1) #print(data.head())\n","y = np.array(data['diagnosis'], ndmin=1).T \n","y = np.where(y=='M',1,0) # class labels\n","data.pop('diagnosis')\n","data.insert(0, \"x0\", pd.Series(np.ones(len(y)))) # appending ones\n","x = np.array(data) # feature matrix"],"execution_count":57,"outputs":[]},{"cell_type":"code","metadata":{"id":"yXEHPLAbmA7a","executionInfo":{"status":"ok","timestamp":1632314739738,"user_tz":-330,"elapsed":3,"user":{"displayName":"Abhay Patwari","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gix32BX_ssvRlYOdFlU8riZsgPg3lrL-_h0Lvui=s64","userId":"16538957145694214892"}}},"source":["m = len(y)\n","nf = 5 #number of folds\n","x_subsets = np.array_split(x, nf)\n","y_subsets = np.array_split(y, nf)"],"execution_count":58,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ufOUJoBRo5uu"},"source":["The following 9 cells have implementation of 9 models of Logistic regression. For each model 5-fold Cross Validation is used to calculate the mean accuracy, sensitivity and specificity."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"PLabpvGU2ICG","executionInfo":{"status":"ok","timestamp":1632315108122,"user_tz":-330,"elapsed":5071,"user":{"displayName":"Abhay Patwari","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gix32BX_ssvRlYOdFlU8riZsgPg3lrL-_h0Lvui=s64","userId":"16538957145694214892"}},"outputId":"25b5bed3-6c6a-4443-c3a7-43cd195d2def"},"source":["# LOR + BGD (optimal parameters from previous question)\n","np.warnings.filterwarnings('ignore', category=np.VisibleDeprecationWarning)\n","\n","alpha = 1.8775510204081631\n","T = 550\n","\n","accuracy_vals = []\n","sensitivity_vals = []\n","specificity_vals = []\n","\n","# 5 fold CV\n","for fold in range(nf):\n","  # test-train split\n","  x_test = x_subsets[fold]\n","  y_test = y_subsets[fold]\n","\n","  x_train = np.concatenate(np.delete(x_subsets, fold, 0), axis=0)\n","  y_train = np.concatenate(np.delete(y_subsets, fold, 0), axis=0)\n","\n","  m_train = len(y_train)\n","  m_test = len(y_test)\n","\n","  # normalizing input data\n","  pp = np.amax(np.abs(x_train), axis=0)\n","  x_train = x_train/pp\n","  x_test = x_test/pp\n","\n","  # training model\n","  w = np.zeros(np.shape(x)[1])\n","  for t in range(T):\n","    for j in range(len(w)):\n","      w[j] = w[j] - (alpha/m_train)*np.dot(h(x_train,w)-y_train,x_train[:,j])\n","  # training complete\n"," \n","  # prediction and performance\n","  pred = np.where(h(x_test,w)>0.5, 1, 0)\n","  tn,fp,fn,tp = conf_matrix(y_test, pred)\n","\n","  sensitivity = tp/(tp+fn)\n","  specificity = tn/(tn+fp)\n","  accuracy = (tp+tn)/(tp+tn+fp+fn)\n","\n","  sensitivity_vals.append(sensitivity)\n","  specificity_vals.append(specificity)\n","  accuracy_vals.append(accuracy)\n","\n","mean_accuracy = np.mean(accuracy_vals)\n","mean_sensitivity = np.mean(sensitivity_vals)\n","mean_specificity = np.mean(specificity_vals)\n","\n","print(\"mean accuracy = {}\".format(mean_accuracy))\n","print(\"mean sensitivity = {}\".format(mean_sensitivity))\n","print(\"mean specificity = {}\".format(mean_specificity))"],"execution_count":61,"outputs":[{"output_type":"stream","name":"stdout","text":["mean accuracy = 0.9648657040832168\n","mean sensitivity = 0.9272288828273162\n","mean specificity = 0.9858255163809435\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Mlkc3C-qG5gF","executionInfo":{"status":"ok","timestamp":1632315278032,"user_tz":-330,"elapsed":4272,"user":{"displayName":"Abhay Patwari","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gix32BX_ssvRlYOdFlU8riZsgPg3lrL-_h0Lvui=s64","userId":"16538957145694214892"}},"outputId":"f758351e-bcfa-467a-b746-1c72dfaf70b4"},"source":["# LOR + L2-Norm + BGD (optimal parameters from previous question)\n","np.warnings.filterwarnings('ignore', category=np.VisibleDeprecationWarning)\n","\n","alpha = 1.8775510204081631\n","T = 550\n","Lambda = 0.0061428571428571435\n","\n","accuracy_vals = []\n","sensitivity_vals = []\n","specificity_vals = []\n","\n","# 5 fold CV\n","for fold in range(nf):\n","  # test-train split\n","  x_test = x_subsets[fold]\n","  y_test = y_subsets[fold]\n","\n","  x_train = np.concatenate(np.delete(x_subsets, fold, 0), axis=0)\n","  y_train = np.concatenate(np.delete(y_subsets, fold, 0), axis=0)\n","\n","  m_train = len(y_train)\n","  m_test = len(y_test)\n","\n","  # normalizing input data\n","  pp = np.amax(np.abs(x_train), axis=0)\n","  x_train = x_train/pp\n","  x_test = x_test/pp\n","\n","  # training model\n","  w = np.zeros(np.shape(x)[1])\n","  for t in range(T):\n","    for j in range(len(w)):\n","      w[j] = (1-alpha*Lambda)*w[j] - (alpha/m_train)*np.dot(h(x_train,w)-y_train,x_train[:,j])\n","  # training complete\n","\n","  # prediction and performance\n","  pred = np.where(h(x_test,w)>0.5, 1, 0)\n","  tn,fp,fn,tp = conf_matrix(y_test, pred)\n","\n","  sensitivity = tp/(tp+fn)\n","  specificity = tn/(tn+fp)\n","  accuracy = (tp+tn)/(tp+tn+fp+fn)\n","\n","  sensitivity_vals.append(sensitivity)\n","  specificity_vals.append(specificity)\n","  accuracy_vals.append(accuracy)\n","\n","mean_accuracy = np.mean(accuracy_vals)\n","mean_sensitivity = np.mean(sensitivity_vals)\n","mean_specificity = np.mean(specificity_vals)\n","\n","print(\"mean accuracy = {}\".format(mean_accuracy))\n","print(\"mean sensitivity = {}\".format(mean_sensitivity))\n","print(\"mean specificity = {}\".format(mean_specificity))"],"execution_count":63,"outputs":[{"output_type":"stream","name":"stdout","text":["mean accuracy = 0.9314547430523211\n","mean sensitivity = 0.8367068895699912\n","mean specificity = 0.9857173693009148\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"uKaPyz6Xkrdw","executionInfo":{"status":"ok","timestamp":1632315366848,"user_tz":-330,"elapsed":4715,"user":{"displayName":"Abhay Patwari","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gix32BX_ssvRlYOdFlU8riZsgPg3lrL-_h0Lvui=s64","userId":"16538957145694214892"}},"outputId":"7822170e-e357-40d4-912f-cdda1174c2ce"},"source":["# LOR + L1-Norm + BGD (optimal parameters from previous question)\n","np.warnings.filterwarnings('ignore', category=np.VisibleDeprecationWarning)\n","\n","alpha = 1.8775510204081631\n","T = 550\n","Lambda = 0.01183673469387755\n","\n","accuracy_vals = []\n","sensitivity_vals = []\n","specificity_vals = []\n","\n","# 5 fold CV\n","for fold in range(nf):\n","  # test-train split\n","  x_test = x_subsets[fold]\n","  y_test = y_subsets[fold]\n","\n","  x_train = np.concatenate(np.delete(x_subsets, fold, 0), axis=0)\n","  y_train = np.concatenate(np.delete(y_subsets, fold, 0), axis=0)\n","\n","  m_train = len(y_train)\n","  m_test = len(y_test)\n","\n","  # normalizing input data\n","  pp = np.amax(np.abs(x_train), axis=0)\n","  x_train = x_train/pp\n","  x_test = x_test/pp\n","\n","  # training model\n","  w = np.zeros(np.shape(x)[1])\n","  for t in range(T):\n","    for j in range(len(w)):\n","      w[j] = w[j] - (alpha/m_train)*np.dot(h(x_train,w)-y_train,x_train[:,j]) - (0.5*Lambda*alpha)*np.sign(w[j])\n","  # training complete\n","\n","  # prediction and performance\n","  pred = np.where(h(x_test,w)>0.5, 1, 0)\n","  tn,fp,fn,tp = conf_matrix(y_test, pred)\n","\n","  sensitivity = tp/(tp+fn)\n","  specificity = tn/(tn+fp)\n","  accuracy = (tp+tn)/(tp+tn+fp+fn)\n","\n","  sensitivity_vals.append(sensitivity)\n","  specificity_vals.append(specificity)\n","  accuracy_vals.append(accuracy)\n","\n","mean_accuracy = np.mean(accuracy_vals)\n","mean_sensitivity = np.mean(sensitivity_vals)\n","mean_specificity = np.mean(specificity_vals)\n","\n","print(\"mean accuracy = {}\".format(mean_accuracy))\n","print(\"mean sensitivity = {}\".format(mean_sensitivity))\n","print(\"mean specificity = {}\".format(mean_specificity))"],"execution_count":64,"outputs":[{"output_type":"stream","name":"stdout","text":["mean accuracy = 0.9384878124514826\n","mean sensitivity = 0.8747696232865732\n","mean specificity = 0.9749747593513833\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"JyFzgQBYk_VA","executionInfo":{"status":"ok","timestamp":1632315534196,"user_tz":-330,"elapsed":3282,"user":{"displayName":"Abhay Patwari","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gix32BX_ssvRlYOdFlU8riZsgPg3lrL-_h0Lvui=s64","userId":"16538957145694214892"}},"outputId":"35d0ac4c-08de-4e22-87d2-ee7a048dd600"},"source":["# LOR + SGD (optimal parameters from previous question)\n","np.warnings.filterwarnings('ignore', category=np.VisibleDeprecationWarning)\n","\n","alpha = 0.19183673469387758\n","T = 450\n","\n","accuracy_vals = []\n","sensitivity_vals = []\n","specificity_vals = []\n","\n","# 5 fold CV\n","for fold in range(nf):\n","  # test-train split\n","  x_test = x_subsets[fold]\n","  y_test = y_subsets[fold]\n","\n","  x_train = np.concatenate(np.delete(x_subsets, fold, 0), axis=0)\n","  y_train = np.concatenate(np.delete(y_subsets, fold, 0), axis=0)\n","\n","  m_train = len(y_train)\n","  m_test = len(y_test)\n","\n","  # normalizing input data\n","  pp = np.amax(np.abs(x_train), axis=0)\n","  x_train = x_train/pp\n","  x_test = x_test/pp\n","\n","  # training model\n","  w = np.zeros(np.shape(x)[1])\n","  for t in range(T):\n","    ind = np.random.randint(m_train)\n","    for j in range(len(w)):\n","      w[j] = w[j] - alpha*(h(x_train,w)[ind] - y_train[ind])*x_train[ind,j]\n","  # training complete\n","\n","  # prediction and performance\n","  pred = np.where(h(x_test,w)>0.5, 1, 0)\n","  tn,fp,fn,tp = conf_matrix(y_test, pred)\n","\n","  sensitivity = tp/(tp+fn)\n","  specificity = tn/(tn+fp)\n","  accuracy = (tp+tn)/(tp+tn+fp+fn)\n","\n","  sensitivity_vals.append(sensitivity)\n","  specificity_vals.append(specificity)\n","  accuracy_vals.append(accuracy)\n","\n","mean_accuracy = np.mean(accuracy_vals)\n","mean_sensitivity = np.mean(sensitivity_vals)\n","mean_specificity = np.mean(specificity_vals)\n","\n","print(\"mean accuracy = {}\".format(mean_accuracy))\n","print(\"mean sensitivity = {}\".format(mean_sensitivity))\n","print(\"mean specificity = {}\".format(mean_specificity))"],"execution_count":75,"outputs":[{"output_type":"stream","name":"stdout","text":["mean accuracy = 0.9209284272628473\n","mean sensitivity = 0.8411535045166898\n","mean specificity = 0.966416929306561\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"TJ-mNlIOlnU3","executionInfo":{"status":"ok","timestamp":1632315619297,"user_tz":-330,"elapsed":3459,"user":{"displayName":"Abhay Patwari","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gix32BX_ssvRlYOdFlU8riZsgPg3lrL-_h0Lvui=s64","userId":"16538957145694214892"}},"outputId":"481eba46-597d-4908-8e6a-7f1028171001"},"source":["# LOR + L2-Norm + SGD (optimal parameters from previous question)\n","np.warnings.filterwarnings('ignore', category=np.VisibleDeprecationWarning)\n","\n","alpha = 0.19183673469387758\n","T = 450\n","Lambda = 0.0011836734693877551\n","\n","accuracy_vals = []\n","sensitivity_vals = []\n","specificity_vals = []\n","\n","# 5 fold CV\n","for fold in range(nf):\n","  # test-train split\n","  x_test = x_subsets[fold]\n","  y_test = y_subsets[fold]\n","\n","  x_train = np.concatenate(np.delete(x_subsets, fold, 0), axis=0)\n","  y_train = np.concatenate(np.delete(y_subsets, fold, 0), axis=0)\n","\n","  m_train = len(y_train)\n","  m_test = len(y_test)\n","\n","  # normalizing input data\n","  pp = np.amax(np.abs(x_train), axis=0)\n","  x_train = x_train/pp\n","  x_test = x_test/pp\n","\n","  # training model\n","  w = np.zeros(np.shape(x)[1])\n","  for t in range(T):\n","    ind = np.random.randint(m_train)\n","    for j in range(len(w)):\n","      w[j] = (1-alpha*Lambda)*w[j] - alpha*(h(x_train,w)[ind] - y_train[ind])*x_train[ind,j]\n","  # training complete\n","\n","  # prediction and performance\n","  pred = np.where(h(x_test,w)>0.5, 1, 0)\n","  tn,fp,fn,tp = conf_matrix(y_test, pred)\n","\n","  sensitivity = tp/(tp+fn)\n","  specificity = tn/(tn+fp)\n","  accuracy = (tp+tn)/(tp+tn+fp+fn)\n","\n","  sensitivity_vals.append(sensitivity)\n","  specificity_vals.append(specificity)\n","  accuracy_vals.append(accuracy)\n","\n","mean_accuracy = np.mean(accuracy_vals)\n","mean_sensitivity = np.mean(sensitivity_vals)\n","mean_specificity = np.mean(specificity_vals)\n","\n","print(\"mean accuracy = {}\".format(mean_accuracy))\n","print(\"mean sensitivity = {}\".format(mean_sensitivity))\n","print(\"mean specificity = {}\".format(mean_specificity))"],"execution_count":77,"outputs":[{"output_type":"stream","name":"stdout","text":["mean accuracy = 0.9138643067846607\n","mean sensitivity = 0.8551021257595603\n","mean specificity = 0.9467574865821028\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"mztuzt6kl79B","executionInfo":{"status":"ok","timestamp":1632315727799,"user_tz":-330,"elapsed":3570,"user":{"displayName":"Abhay Patwari","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gix32BX_ssvRlYOdFlU8riZsgPg3lrL-_h0Lvui=s64","userId":"16538957145694214892"}},"outputId":"77859c24-8fa5-401a-e6b0-e7be61879e83"},"source":["# LOR + L1-Norm + SGD (optimal parameters from previous question)\n","np.warnings.filterwarnings('ignore', category=np.VisibleDeprecationWarning)\n","\n","alpha = 0.19183673469387758\n","T = 450\n","Lambda = 0.0013673469387755102\n","\n","accuracy_vals = []\n","sensitivity_vals = []\n","specificity_vals = []\n","\n","# 5 fold CV\n","for fold in range(nf):\n","  # test-train split\n","  x_test = x_subsets[fold]\n","  y_test = y_subsets[fold]\n","\n","  x_train = np.concatenate(np.delete(x_subsets, fold, 0), axis=0)\n","  y_train = np.concatenate(np.delete(y_subsets, fold, 0), axis=0)\n","\n","  m_train = len(y_train)\n","  m_test = len(y_test)\n","\n","  # normalizing input data\n","  pp = np.amax(np.abs(x_train), axis=0)\n","  x_train = x_train/pp\n","  x_test = x_test/pp\n","\n","  # training model\n","  w = np.zeros(np.shape(x)[1])\n","  for t in range(T):\n","    ind = np.random.randint(m_train)\n","    for j in range(len(w)):\n","      w[j] = w[j] - alpha*(h(x_train,w)[ind] - y_train[ind])*x_train[ind,j] - (0.5*alpha*Lambda)*np.sign(w[j])\n","  # training complete\n","\n","  # prediction and performance\n","  pred = np.where(h(x_test,w)>0.5, 1, 0)\n","  tn,fp,fn,tp = conf_matrix(y_test, pred)\n","\n","  sensitivity = tp/(tp+fn)\n","  specificity = tn/(tn+fp)\n","  accuracy = (tp+tn)/(tp+tn+fp+fn)\n","\n","  sensitivity_vals.append(sensitivity)\n","  specificity_vals.append(specificity)\n","  accuracy_vals.append(accuracy)\n","\n","mean_accuracy = np.mean(accuracy_vals)\n","mean_sensitivity = np.mean(sensitivity_vals)\n","mean_specificity = np.mean(specificity_vals)\n","\n","print(\"mean accuracy = {}\".format(mean_accuracy))\n","print(\"mean sensitivity = {}\".format(mean_sensitivity))\n","print(\"mean specificity = {}\".format(mean_specificity))"],"execution_count":81,"outputs":[{"output_type":"stream","name":"stdout","text":["mean accuracy = 0.9051079024996118\n","mean sensitivity = 0.7680730472307888\n","mean specificity = 0.9826241475940203\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ANGRceL5mUD5","executionInfo":{"status":"ok","timestamp":1632315913669,"user_tz":-330,"elapsed":67289,"user":{"displayName":"Abhay Patwari","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gix32BX_ssvRlYOdFlU8riZsgPg3lrL-_h0Lvui=s64","userId":"16538957145694214892"}},"outputId":"fd65d749-e548-4852-bae4-75354c23b6f3"},"source":["# LOR + MBGD (optimal parameters from previous question)\n","np.warnings.filterwarnings('ignore', category=np.VisibleDeprecationWarning)\n","\n","nb = 32 #batch size\n","rng = np.random.default_rng()\n","\n","alpha = 0.1\n","T = 350\n","\n","accuracy_vals = []\n","sensitivity_vals = []\n","specificity_vals = []\n","\n","# 5 fold CV\n","for fold in range(nf):\n","  # test-train split\n","  x_test = x_subsets[fold]\n","  y_test = y_subsets[fold]\n","\n","  x_train = np.concatenate(np.delete(x_subsets, fold, 0), axis=0)\n","  y_train = np.concatenate(np.delete(y_subsets, fold, 0), axis=0)\n","\n","  m_train = len(y_train)\n","  m_test = len(y_test)\n","\n","  # normalizing input data\n","  pp = np.amax(np.abs(x_train), axis=0)\n","  x_train = x_train/pp\n","  x_test = x_test/pp\n","\n","  # training model\n","  w = np.zeros(np.shape(x)[1])\n","  for t in range(T):\n","    ind = rng.choice(m_train, nb, replace=False)\n","    for j in range(len(w)):\n","      w[j] = w[j] - (alpha/nb)*np.sum([(h(x_train,w)[i]-y_train[i])*x_train[i,j] for i in ind])\n","  # training complete\n","\n","  # prediction and performance\n","  pred = np.where(h(x_test,w)>0.5, 1, 0)\n","  tn,fp,fn,tp = conf_matrix(y_test, pred)\n","\n","  sensitivity = tp/(tp+fn)\n","  specificity = tn/(tn+fp)\n","  accuracy = (tp+tn)/(tp+tn+fp+fn)\n","\n","  sensitivity_vals.append(sensitivity)\n","  specificity_vals.append(specificity)\n","  accuracy_vals.append(accuracy)\n","\n","mean_accuracy = np.mean(accuracy_vals)\n","mean_sensitivity = np.mean(sensitivity_vals)\n","mean_specificity = np.mean(specificity_vals)\n","\n","print(\"mean accuracy = {}\".format(mean_accuracy))\n","print(\"mean sensitivity = {}\".format(mean_sensitivity))\n","print(\"mean specificity = {}\".format(mean_specificity))"],"execution_count":82,"outputs":[{"output_type":"stream","name":"stdout","text":["mean accuracy = 0.9103555348548362\n","mean sensitivity = 0.7892437231251908\n","mean specificity = 0.9801007157266806\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Mq1h9A1OnGZp","executionInfo":{"status":"ok","timestamp":1632316108791,"user_tz":-330,"elapsed":67026,"user":{"displayName":"Abhay Patwari","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gix32BX_ssvRlYOdFlU8riZsgPg3lrL-_h0Lvui=s64","userId":"16538957145694214892"}},"outputId":"c7f896d2-92d8-491b-f1d1-72bb9b107d6c"},"source":["# LOR + L2-Norm + MBGD (optimal parameters from previous question)\n","np.warnings.filterwarnings('ignore', category=np.VisibleDeprecationWarning)\n","\n","nb = 32 #batch size\n","rng = np.random.default_rng()\n","\n","alpha = 0.1\n","T = 350\n","Lambda = 0.01\n","\n","accuracy_vals = []\n","sensitivity_vals = []\n","specificity_vals = []\n","\n","# 5 fold CV\n","for fold in range(nf):\n","  # test-train split\n","  x_test = x_subsets[fold]\n","  y_test = y_subsets[fold]\n","\n","  x_train = np.concatenate(np.delete(x_subsets, fold, 0), axis=0)\n","  y_train = np.concatenate(np.delete(y_subsets, fold, 0), axis=0)\n","\n","  m_train = len(y_train)\n","  m_test = len(y_test)\n","\n","  # normalizing input data\n","  pp = np.amax(np.abs(x_train), axis=0)\n","  x_train = x_train/pp\n","  x_test = x_test/pp\n","\n","  # training model\n","  w = np.zeros(np.shape(x)[1])\n","  for t in range(T):\n","    ind = rng.choice(m_train, nb, replace=False)\n","    for j in range(len(w)):\n","      w[j] = (1-alpha*Lambda)*w[j] - (alpha/nb)*np.sum([(h(x_train,w)[i]-y_train[i])*x_train[i,j] for i in ind])\n","  # training complete\n","\n","  # prediction and performance\n","  pred = np.where(h(x_test,w)>0.5, 1, 0)\n","  tn,fp,fn,tp = conf_matrix(y_test, pred)\n","\n","  sensitivity = tp/(tp+fn)\n","  specificity = tn/(tn+fp)\n","  accuracy = (tp+tn)/(tp+tn+fp+fn)\n","\n","  sensitivity_vals.append(sensitivity)\n","  specificity_vals.append(specificity)\n","  accuracy_vals.append(accuracy)\n","\n","mean_accuracy = np.mean(accuracy_vals)\n","mean_sensitivity = np.mean(sensitivity_vals)\n","mean_specificity = np.mean(specificity_vals)\n","\n","print(\"mean accuracy = {}\".format(mean_accuracy))\n","print(\"mean sensitivity = {}\".format(mean_sensitivity))\n","print(\"mean specificity = {}\".format(mean_specificity))"],"execution_count":83,"outputs":[{"output_type":"stream","name":"stdout","text":["mean accuracy = 0.9086011488899238\n","mean sensitivity = 0.7797778527227796\n","mean specificity = 0.9826241475940203\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gkeAVFlKoWd0","executionInfo":{"status":"ok","timestamp":1632316375554,"user_tz":-330,"elapsed":67273,"user":{"displayName":"Abhay Patwari","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gix32BX_ssvRlYOdFlU8riZsgPg3lrL-_h0Lvui=s64","userId":"16538957145694214892"}},"outputId":"75b95126-bcbc-40cf-e521-550c7443df36"},"source":["# LOR + L1-Norm + MBGD (optimal parameters from previous question)\n","np.warnings.filterwarnings('ignore', category=np.VisibleDeprecationWarning)\n","\n","nb = 32 #batch size\n","rng = np.random.default_rng()\n","\n","alpha = 0.1\n","T = 350\n","Lambda = 0.01\n","\n","accuracy_vals = []\n","sensitivity_vals = []\n","specificity_vals = []\n","\n","# 5 fold CV\n","for fold in range(nf):\n","  # test-train split\n","  x_test = x_subsets[fold]\n","  y_test = y_subsets[fold]\n","\n","  x_train = np.concatenate(np.delete(x_subsets, fold, 0), axis=0)\n","  y_train = np.concatenate(np.delete(y_subsets, fold, 0), axis=0)\n","\n","  m_train = len(y_train)\n","  m_test = len(y_test)\n","\n","  # normalizing input data\n","  pp = np.amax(np.abs(x_train), axis=0)\n","  x_train = x_train/pp\n","  x_test = x_test/pp\n","\n","  # training model\n","  w = np.zeros(np.shape(x)[1])\n","  for t in range(T):\n","    ind = rng.choice(m_train, nb, replace=False)\n","    for j in range(len(w)):\n","      w[j] = w[j] - (alpha/nb)*np.sum([(h(x_train,w)[i]-y_train[i])*x_train[i,j] for i in ind]) - (0.5*alpha*Lambda)*np.sign(w[j])\n","  # training complete\n","\n","  # prediction and performance\n","  pred = np.where(h(x_test,w)>0.5, 1, 0)\n","  tn,fp,fn,tp = conf_matrix(y_test, pred)\n","\n","  sensitivity = tp/(tp+fn)\n","  specificity = tn/(tn+fp)\n","  accuracy = (tp+tn)/(tp+tn+fp+fn)\n","\n","  sensitivity_vals.append(sensitivity)\n","  specificity_vals.append(specificity)\n","  accuracy_vals.append(accuracy)\n","\n","mean_accuracy = np.mean(accuracy_vals)\n","mean_sensitivity = np.mean(sensitivity_vals)\n","mean_specificity = np.mean(specificity_vals)\n","\n","print(\"mean accuracy = {}\".format(mean_accuracy))\n","print(\"mean sensitivity = {}\".format(mean_sensitivity))\n","print(\"mean specificity = {}\".format(mean_specificity))"],"execution_count":84,"outputs":[{"output_type":"stream","name":"stdout","text":["mean accuracy = 0.9120943952802361\n","mean sensitivity = 0.7830589515009517\n","mean specificity = 0.9853638736214176\n"]}]}]}