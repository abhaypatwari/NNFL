{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Q_8.ipynb","provenance":[],"collapsed_sections":[],"mount_file_id":"1g2i4wzclVBIPz0WXM4rs04ZBuxxLT1NE","authorship_tag":"ABX9TyOex2Vww7iiI+JDi+bQNj73"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","metadata":{"id":"vJY8EtV-RCAw","executionInfo":{"status":"ok","timestamp":1638264079371,"user_tz":-330,"elapsed":432,"user":{"displayName":"Abhay Patwari","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gix32BX_ssvRlYOdFlU8riZsgPg3lrL-_h0Lvui=s64","userId":"16538957145694214892"}}},"source":["import numpy as np\n","import pandas as pd\n","\n","def holdout(data, trainp, validp):\n","  m = np.shape(data)[0]\n","\n","  train = data[0 : int(np.floor(m*trainp/100))]\n","  valid = data[int(np.floor(m*trainp/100)) : int(np.floor(m*trainp/100))+int(np.floor(m*validp/100))]\n","  test = data[int(np.floor(m*trainp/100))+int(np.floor(m*validp/100)) : None]\n","\n","  y_train = train[:,-1] #shape = (rows,)\n","  x_train = np.delete(train, -1, axis=1)\n","\n","  y_valid = valid[:,-1] #shape = (rows,)\n","  x_valid = np.delete(valid, -1, axis=1)\n","\n","  y_test = test[:,-1] #shape = (rows,)\n","  x_test = np.delete(test, -1, axis=1)\n","\n","  return x_train,x_valid,x_test,y_train,y_valid,y_test\n","\n","def onevall(k,y):\n","  return np.where(y==k, 1, -1)\n","\n","def rbf_kernel(x1, x2):\n","  return np.exp(-np.linalg.norm(x1-x2)**2 / (2 * 2.25**2)) # fixed sigma=2.25\n","\n","def polynomial_kernel(x1, x2):\n","  return (np.dot(x1, x2))**2 # fixed degree=2\n","\n","def gram_matrix(x1, x2, kernel):\n","  if kernel=='rbf':\n","    K = np.zeros((x1.shape[0],x2.shape[0]))\n","    for i in range(x1.shape[0]):\n","      for j in range(x2.shape[0]):\n","        K[i,j] = rbf_kernel(x1[i], x2[j])\n","    return K\n"," \n","  if kernel=='polynomial':\n","    K = np.zeros((x1.shape[0],x2.shape[0]))\n","    for i in range(x1.shape[0]):\n","      for j in range(x2.shape[0]):\n","        K[i,j] = polynomial_kernel(x1[i], x2[j])\n","    return K\n","\n","def calculate_eta(x1,x2, kernel):\n","  if kernel=='rbf':\n","    return (rbf_kernel(x1,x1) + rbf_kernel(x2,x2) -2*rbf_kernel(x1,x2))\n","  if kernel=='polynomial':\n","    return (polynomial_kernel(x1,x1) + polynomial_kernel(x2,x2) -2*polynomial_kernel(x1,x2))\n","\n","def calculate_L_H(C, alpha_j, alpha_i, y_j, y_i):\n","  if(y_i != y_j):\n","    return (max(0, alpha_j - alpha_i), min(C, C - alpha_i + alpha_j))\n","  else:\n","    return (max(0, alpha_i + alpha_j - C), min(C, alpha_i + alpha_j))\n","\n","def SVM(x_train, y_train, C, epsilon, max_iters, kernel):\n","  K = gram_matrix(x_train,x_train,kernel)\n","  alpha = np.zeros(x_train.shape[0]) # lagrange multipliers\n","  iters = 0\n","  b = 0\n","\n","  while True:\n","    alpha_old = alpha\n","    iters += 1\n","    for j in range(x_train.shape[0]):\n","      i = np.random.choice(np.delete(np.arange(x_train.shape[0]),np.where(np.arange(x_train.shape[0])==j)))\n","      xi, xj, yi, yj = x_train[i,:], x_train[j,:], y_train[i], y_train[j]\n","      L, H = calculate_L_H(C, alpha[j], alpha[i], yj, yi) # higher and lower bounds\n","      if L==H:\n","        continue\n","\n","      eta = calculate_eta(xi, xj, kernel)\n","      if eta <= 0:\n","        continue\n","\n","      E_i = np.sum(alpha*y_train*K[:,i]) - b - yi\n","      E_j = np.sum(alpha*y_train*K[:,j]) - b - yj\n","    \n","      alpha_j_old = alpha[j]\n","      alpha_i_old = alpha[i]\n","\n","      alpha[j] = alpha[j] + (yj * (E_i - E_j))/eta\n","      alpha[j] = max(alpha[j], L)\n","      alpha[j] = min(alpha[j], H)\n","\n","      alpha[i] = alpha_i_old + yi*yj * (alpha_j_old - alpha[j])\n","\n","      b1 = E_i + yi*(alpha[i] - alpha_i_old)*K[i,i] + yj*(alpha[j] - alpha_j_old)*K[i,j] + b \n","      b2 = E_j + yi*(alpha[i] - alpha_i_old)*K[i,j] + yj*(alpha[j] - alpha_j_old)*K[j,j] + b\n","      if alpha[i]>L and alpha[i]<H:\n","        b = b1\n","      elif alpha[j]>L and alpha[j]<H:\n","        b = b2\n","      else :\n","        b = (b1+b2)/2\n","\n","    diff = np.linalg.norm(alpha_old - alpha)\n","    if diff < epsilon:\n","      break\n","    if iters >= max_iters:\n","      break\n","  \n","  n_sv = np.sum(alpha>0) # number of support vectors\n","  alpha_sv = alpha[np.where(alpha>0)[0]]\n","  x_sv = x_train[np.where(alpha>0)[0],:]\n","  y_sv = y_train[np.where(alpha>0)[0]]\n","  w = (alpha_sv*y_sv) @ x_sv\n","\n","  return w, b, diff\n","\n","def performance(y, pred):\n","  m = np.zeros((3,3)) # confusion matrix\n","  for p in range(len(pred)):\n","    if pred[p]==1 and y[p]==1:\n","      m[0,0]+=1\n","    if pred[p]==2 and y[p]==2:\n","      m[1,1]+=1\n","    if pred[p]==3 and y[p]==3:\n","      m[2,2]+=1\n","    if pred[p]==1 and y[p]==2:\n","      m[1,0]+=1\n","    if pred[p]==1 and y[p]==3:\n","      m[2,0]+=1\n","    if pred[p]==2 and y[p]==1:\n","      m[0,1]+=1\n","    if pred[p]==2 and y[p]==3:\n","      m[2,1]+=1\n","    if pred[p]==3 and y[p]==1:\n","      m[0,2]+=1\n","    if pred[p]==3 and y[p]==2:\n","      m[1,2]+=1\n","  ind_accuracy = [m[0,0]/np.sum(m[0,:]), m[1,1]/np.sum(m[1,:]), m[2,2]/np.sum(m[2,:])]\n","  accuracy = (m[0,0]+m[1,1]+m[2,2])/np.sum(m)\n","  return ind_accuracy, accuracy"],"execution_count":10,"outputs":[]},{"cell_type":"code","metadata":{"id":"uxJx61jNXTg0","executionInfo":{"status":"ok","timestamp":1638264082635,"user_tz":-330,"elapsed":1830,"user":{"displayName":"Abhay Patwari","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gix32BX_ssvRlYOdFlU8riZsgPg3lrL-_h0Lvui=s64","userId":"16538957145694214892"}}},"source":["data = pd.read_excel('/content/drive/MyDrive/NNFL Assignments (Aug 2021)/Assignment 2/data5.xlsx')\n","cols = np.array(data.columns, ndmin=2)\n","data = data.to_numpy()\n","data = np.concatenate((cols,data), axis=0)\n","\n","# shuffle & train-test-valid-split\n","np.random.seed(0)\n","np.random.shuffle(data)\n","x_train, x_valid, x_test, y_train, y_valid, y_test = holdout(data, 70, 10)\n","\n","# normalizing input data\n","mu = np.mean(x_train, axis=0)\n","std = np.std(x_train, axis=0)\n","\n","x_train = (x_train-mu)/std\n","x_valid = (x_valid-mu)/std\n","x_test = (x_test-mu)/std"],"execution_count":11,"outputs":[]},{"cell_type":"code","metadata":{"id":"yNZ6-dl8XagE","executionInfo":{"status":"ok","timestamp":1638264082637,"user_tz":-330,"elapsed":28,"user":{"displayName":"Abhay Patwari","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gix32BX_ssvRlYOdFlU8riZsgPg3lrL-_h0Lvui=s64","userId":"16538957145694214892"}}},"source":["# one vs. all encoding output data\n","y_train1 = onevall(1,y_train)\n","y_train2 = onevall(2,y_train)\n","y_train3 = onevall(3,y_train)\n","y_test1 = onevall(1,y_test)\n","y_test2 = onevall(2,y_test)\n","y_test3 = onevall(3,y_test)"],"execution_count":12,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"UK7uH7WOv3KQ"},"source":["RBF KERNEL"]},{"cell_type":"code","metadata":{"id":"wYJ7DIk8uBAC","executionInfo":{"status":"ok","timestamp":1638264082639,"user_tz":-330,"elapsed":28,"user":{"displayName":"Abhay Patwari","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gix32BX_ssvRlYOdFlU8riZsgPg3lrL-_h0Lvui=s64","userId":"16538957145694214892"}}},"source":["# SVM hyperparameters\n","C = 13\n","epsilon = 1e-3\n","max_iters = 1000\n","kernel = 'rbf'"],"execution_count":13,"outputs":[]},{"cell_type":"code","metadata":{"id":"677wKnulXeR3","executionInfo":{"status":"ok","timestamp":1638264082640,"user_tz":-330,"elapsed":28,"user":{"displayName":"Abhay Patwari","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gix32BX_ssvRlYOdFlU8riZsgPg3lrL-_h0Lvui=s64","userId":"16538957145694214892"}}},"source":["# training 3 models\n","w1, b1, diff1 = SVM(x_train, y_train1, C, epsilon, max_iters, kernel)\n","w2, b2, diff2 = SVM(x_train, y_train2, C, epsilon, max_iters, kernel)\n","w3, b3, diff3 = SVM(x_train, y_train3, C, epsilon, max_iters, kernel)"],"execution_count":14,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6xzd18HwYbjB","executionInfo":{"status":"ok","timestamp":1638264082641,"user_tz":-330,"elapsed":28,"user":{"displayName":"Abhay Patwari","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gix32BX_ssvRlYOdFlU8riZsgPg3lrL-_h0Lvui=s64","userId":"16538957145694214892"}},"outputId":"7884fb2a-7dfa-4d66-8c3d-4873d49a9746"},"source":["# testing\n","pred_1 = ((w1.T @ x_test.T) + b1)\n","pred_2 = ((w2.T @ x_test.T) + b2)\n","pred_3 = ((w3.T @ x_test.T) + b3)\n","\n","# pred vector\n","pred = np.zeros((x_test.shape[0],3))\n","for i in range(x_test.shape[0]):\n","  pred[i] = [pred_1[i], pred_2[i], pred_3[i]]\n","\n","# final prediction\n","y_pred = np.argmax(pred, axis=1) +1\n","\n","# performance\n","ind_accuracy, accuracy = performance(y_test, y_pred)\n","print(\"accuracy of class 1 = {}\".format(ind_accuracy[0]))\n","print(\"accuracy of class 2 = {}\".format(ind_accuracy[1]))\n","print(\"accuracy of class 3 = {}\".format(ind_accuracy[2]))\n","print(\"overall accuracy of classifier = {}\".format(accuracy))"],"execution_count":15,"outputs":[{"output_type":"stream","name":"stdout","text":["accuracy of class 1 = 0.5\n","accuracy of class 2 = 1.0\n","accuracy of class 3 = 1.0\n","overall accuracy of classifier = 0.8809523809523809\n"]}]},{"cell_type":"markdown","metadata":{"id":"djd1qTGsvw-c"},"source":["POLYNOMIAL KERNEL\n"]},{"cell_type":"code","metadata":{"id":"-EUE78rYveSa","executionInfo":{"status":"ok","timestamp":1638264082645,"user_tz":-330,"elapsed":26,"user":{"displayName":"Abhay Patwari","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gix32BX_ssvRlYOdFlU8riZsgPg3lrL-_h0Lvui=s64","userId":"16538957145694214892"}}},"source":["# SVM hyperparameters\n","C = 13\n","epsilon = 1e-3\n","max_iters = 1000\n","kernel = 'polynomial'"],"execution_count":16,"outputs":[]},{"cell_type":"code","metadata":{"id":"d17E4VzHvo-o","executionInfo":{"status":"ok","timestamp":1638264082646,"user_tz":-330,"elapsed":27,"user":{"displayName":"Abhay Patwari","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gix32BX_ssvRlYOdFlU8riZsgPg3lrL-_h0Lvui=s64","userId":"16538957145694214892"}}},"source":["# training 3 models\n","w1, b1, diff1 = SVM(x_train, y_train1, C, epsilon, max_iters, kernel)\n","w2, b2, diff2 = SVM(x_train, y_train2, C, epsilon, max_iters, kernel)\n","w3, b3, diff3 = SVM(x_train, y_train3, C, epsilon, max_iters, kernel)"],"execution_count":17,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"OVV_x0z6vsuY","executionInfo":{"status":"ok","timestamp":1638264082648,"user_tz":-330,"elapsed":27,"user":{"displayName":"Abhay Patwari","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gix32BX_ssvRlYOdFlU8riZsgPg3lrL-_h0Lvui=s64","userId":"16538957145694214892"}},"outputId":"9de6e5f9-4f1b-47ad-afee-8d28ab946231"},"source":["# testing\n","pred_1 = ((w1.T @ x_test.T) + b1)\n","pred_2 = ((w2.T @ x_test.T) + b2)\n","pred_3 = ((w3.T @ x_test.T) + b3)\n","\n","# pred vector\n","pred = np.zeros((x_test.shape[0],3))\n","for i in range(x_test.shape[0]):\n","  pred[i] = [pred_1[i], pred_2[i], pred_3[i]]\n","\n","# final prediction\n","y_pred = np.argmax(pred, axis=1) +1\n","\n","# performance\n","ind_accuracy, accuracy = performance(y_test, y_pred)\n","print(\"accuracy of class 1 = {}\".format(ind_accuracy[0]))\n","print(\"accuracy of class 2 = {}\".format(ind_accuracy[1]))\n","print(\"accuracy of class 3 = {}\".format(ind_accuracy[2]))\n","print(\"overall accuracy of classifier = {}\".format(accuracy))"],"execution_count":18,"outputs":[{"output_type":"stream","name":"stdout","text":["accuracy of class 1 = 0.0\n","accuracy of class 2 = 1.0\n","accuracy of class 3 = 1.0\n","overall accuracy of classifier = 0.7619047619047619\n"]}]}]}