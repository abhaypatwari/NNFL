{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Q3.ipynb","provenance":[],"collapsed_sections":[],"mount_file_id":"1d-a4MwUTUc-StWcJ5Fz8GNEIlg5joyA7","authorship_tag":"ABX9TyOBduiX+Nub+gmEnrySAHz9"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","metadata":{"id":"YPDagL72HcVG","executionInfo":{"status":"ok","timestamp":1637310232855,"user_tz":-330,"elapsed":474,"user":{"displayName":"Abhay Patwari","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gix32BX_ssvRlYOdFlU8riZsgPg3lrL-_h0Lvui=s64","userId":"16538957145694214892"}}},"source":["import numpy as np\n","import pandas as pd\n","\n","def sigmoid(x,w):\n","  return 1/(1 + np.exp(-1*np.dot(x,w.T)))\n","\n","def pred(y):\n","  return (np.argmax(y, axis=1) + 1)\n","\n","def holdout(data, trainp, validp):\n","  m = np.shape(data)[0]\n","\n","  train = data[0 : int(np.floor(m*trainp/100))]\n","  valid = data[int(np.floor(m*trainp/100)) : int(np.floor(m*trainp/100))+int(np.floor(m*validp/100))]\n","  test = data[int(np.floor(m*trainp/100))+int(np.floor(m*validp/100)) : None]\n","\n","  y_train = train[:,-1] #shape = (rows,)\n","  x_train = np.delete(train, -1, axis=1)\n","\n","  y_valid = valid[:,-1] #shape = (rows,)\n","  x_valid = np.delete(valid, -1, axis=1)\n","\n","  y_test = test[:,-1] #shape = (rows,)\n","  x_test = np.delete(test, -1, axis=1)\n","\n","  return x_train,x_valid,x_test,y_train,y_valid,y_test\n","\n","def five_fold(data):\n","  y = data[:,-1]\n","  x = np.delete(data, -1, axis=1)\n","  x_subsets = np.array_split(x, 5)\n","  y_subsets = np.array_split(y, 5)\n","  return x_subsets,y_subsets\n","\n","def appendones(x):\n","  m = np.shape(x)[0]\n","  return np.concatenate((np.ones((m,1)),x), axis=1)\n","\n","def one_hot_encode(y):\n","  len = np.size(y)\n","  encoded_y = np.zeros((len,3))\n","  for i in range(len):\n","    if y[i] == 1:\n","      encoded_y[i,0] = 1\n","    if y[i] == 2:\n","      encoded_y[i,1] = 1\n","    if y[i] == 3:\n","      encoded_y[i,2] = 1\n","  return encoded_y\n","\n","def performance(y, pred):\n","  m = np.zeros((3,3)) # confusion matrix\n","  for p in range(len(pred)):\n","    if pred[p]==1 and y[p]==1:\n","      m[0,0]+=1\n","    if pred[p]==2 and y[p]==2:\n","      m[1,1]+=1\n","    if pred[p]==3 and y[p]==3:\n","      m[2,2]+=1\n","    if pred[p]==1 and y[p]==2:\n","      m[1,0]+=1\n","    if pred[p]==1 and y[p]==3:\n","      m[2,0]+=1\n","    if pred[p]==2 and y[p]==1:\n","      m[0,1]+=1\n","    if pred[p]==2 and y[p]==3:\n","      m[2,1]+=1\n","    if pred[p]==3 and y[p]==1:\n","      m[0,2]+=1\n","    if pred[p]==3 and y[p]==2:\n","      m[1,2]+=1\n","  ind_accuracy = [m[0,0]/np.sum(m[0,:]), m[1,1]/np.sum(m[1,:]), m[2,2]/np.sum(m[2,:])]\n","  accuracy = (m[0,0]+m[1,1]+m[2,2])/np.sum(m)\n","  return ind_accuracy, accuracy"],"execution_count":3,"outputs":[]},{"cell_type":"code","metadata":{"id":"kaqOfqgixyKB","executionInfo":{"status":"ok","timestamp":1637310239719,"user_tz":-330,"elapsed":1190,"user":{"displayName":"Abhay Patwari","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gix32BX_ssvRlYOdFlU8riZsgPg3lrL-_h0Lvui=s64","userId":"16538957145694214892"}}},"source":["data = pd.read_excel('/content/drive/MyDrive/NNFL Assignments (Aug 2021)/Assignment 2/data5.xlsx')\n","cols = np.array(data.columns, ndmin=2)\n","data = data.to_numpy()\n","data = np.concatenate((cols,data), axis=0)\n","\n","# shuffle & train-test-valid-split\n","np.random.seed(0)\n","np.random.shuffle(data)\n","x_train, x_valid, x_test, y_train, y_valid, y_test = holdout(data, 70, 10)\n","\n","# normalizing input data\n","mu = np.mean(x_train, axis=0)\n","std = np.std(x_train, axis=0)\n","\n","x_train = (x_train-mu)/std\n","x_valid = (x_valid-mu)/std\n","x_test = (x_test-mu)/std\n","\n","# one-hot-encoding output data\n","y_train_coded = one_hot_encode(y_train)\n","y_valid_coded = one_hot_encode(y_valid)\n","y_test_coded = one_hot_encode(y_test)\n","\n","# appending ones (input for bias)\n","x_train = appendones(x_train)\n","x_valid = appendones(x_valid)\n","x_test = appendones(x_test)\n","\n","m_train = np.size(y_train)\n","m_valid = np.size(y_valid)\n","m_test = np.size(y_test)\n","\n","ni = np.shape(x_train)[1] # number of input neurons (features)\n","no = 3 # number of ouput neurons (classes)"],"execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"N1Ns5u-Mk3zb","executionInfo":{"status":"ok","timestamp":1637303672373,"user_tz":-330,"elapsed":2266,"user":{"displayName":"Abhay Patwari","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gix32BX_ssvRlYOdFlU8riZsgPg3lrL-_h0Lvui=s64","userId":"16538957145694214892"}},"outputId":"25fc838e-a19e-42b5-e7d0-5d8fb16de70f"},"source":["# grid search for scale parameter to choose number of hidden neurons\n","scale = list(np.arange(2,11))\n","\n","accuracy_vals = np.zeros(((len(scale),len(scale))))\n","for s1 in scale:\n","  for s2 in scale:\n","    nh1 = (m_train/(s1*(ni + no))).astype(int)\n","    nh2 = (m_train/(s2*(nh1 + no))).astype(int)\n","\n","    T = 200 #iters\n","    alpha = 0.1 #learning rate\n","\n","    # random weights\n","    np.random.seed(0)\n","    w1i = np.random.randn(nh1, ni)\n","    np.random.seed(0)\n","    w21 = np.random.randn(nh2, nh1)\n","    np.random.seed(0)\n","    wo2 = np.random.randn(no, nh2)\n","\n","    # training\n","    for i in range(T):\n","\n","      # forward path propagation\n","      y1 = sigmoid(x_train,w1i)\n","      y2 = sigmoid(y1,w21)\n","      y =  sigmoid(y2,wo2)\n","\n","      # back propagation\n","      \n","      \"\"\"updating output layer weights\"\"\"\n","      delta = (y_train_coded - y) * y * (1 - y)\n","      wo2 = wo2 + alpha * np.dot(delta.T, y2)\n","\n","      \"\"\"updating 2nd hidden layer weights\"\"\"\n","      delta = y2*(1-y2) * np.dot(delta,wo2)\n","      w21 = w21 + alpha * np.dot(delta.T, y1)\n","\n","      \"\"\"updating 1st hidden layer weights\"\"\"\n","      delta = y1*(1-y1) * np.dot(delta,w21)\n","      w1i = w1i + alpha * np.dot(delta.T, x_train)\n","\n","    # validation\n","    y1 = sigmoid(x_valid,w1i)\n","    y2 = sigmoid(y1,w21)\n","    y =  sigmoid(y2,wo2)\n","\n","    y = pred(y)\n","\n","    # performance measures\n","    ind_accuracy, accuracy = performance(y_valid, y)\n","    accuracy_vals[scale.index(s1)][scale.index(s2)] = accuracy\n","    \n","# index of maximum accuracy\n","index = np.unravel_index(np.argmax(accuracy_vals, axis=None), accuracy_vals.shape)\n","    \n","print(\"maximum validation accuracy = {}\".format(accuracy_vals[index]))\n","print(\"index = {}\".format(index))\n","print(\"Optimal s1 value = {}\\nOptimal s2 value = {}\".format(scale[index[0]],scale[index[1]]))"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["maximum validation accuracy = 1.0\n","index = (0, 0)\n","Optimal s1 value = 2\n","Optimal s2 value = 2\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"tYe50dQR5_TD","executionInfo":{"status":"ok","timestamp":1637303967723,"user_tz":-330,"elapsed":842,"user":{"displayName":"Abhay Patwari","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gix32BX_ssvRlYOdFlU8riZsgPg3lrL-_h0Lvui=s64","userId":"16538957145694214892"}},"outputId":"f765d867-7702-4849-de1c-1ffb0e191944"},"source":["# optimal number of hidden neurons\n","s1 = 2\n","s2 = 2\n","nh1 = int(m_train/(s1*(ni + no)))\n","nh2 = int(m_train/(s2*(nh1 + no)))\n","\n","print(nh1, nh2)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["6 8\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Wr-xunG-zVOV","executionInfo":{"status":"ok","timestamp":1637303900902,"user_tz":-330,"elapsed":601,"user":{"displayName":"Abhay Patwari","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gix32BX_ssvRlYOdFlU8riZsgPg3lrL-_h0Lvui=s64","userId":"16538957145694214892"}},"outputId":"fa8fc538-7163-46ac-c2f7-2f3ace6362e6"},"source":["nh1 = 6 # number of neurons in first hidden layer\n","nh2 = 8 # number of neurons in second hidden layer\n","\n","T = 200 #iters\n","alpha = 0.1 #learning rate\n","\n","# random weights\n","np.random.seed(0)\n","w1i = np.random.randn(nh1, ni)\n","np.random.seed(0)\n","w21 = np.random.randn(nh2, nh1)\n","np.random.seed(0)\n","wo2 = np.random.randn(no, nh2)\n","\n","# training\n","for i in range(T):\n","\n","  # forward path propagation\n","  y1 = sigmoid(x_train,w1i)\n","  y2 = sigmoid(y1,w21)\n","  y =  sigmoid(y2,wo2)\n","\n","  # back propagation\n","  \n","  \"\"\"updating output layer weights\"\"\"\n","  delta = (y_train_coded - y) * y * (1 - y)\n","  wo2 = wo2 + alpha * np.dot(delta.T, y2)\n","\n","  \"\"\"updating 2nd hidden layer weights\"\"\"\n","  delta = y2*(1-y2) * np.dot(delta,wo2)\n","  w21 = w21 + alpha * np.dot(delta.T, y1)\n","\n","  \"\"\"updating 1st hidden layer weights\"\"\"\n","  delta = y1*(1-y1) * np.dot(delta,w21)\n","  w1i = w1i + alpha * np.dot(delta.T, x_train)\n","\n","# testing\n","y1 = sigmoid(x_test,w1i)\n","y2 = sigmoid(y1,w21)\n","y =  sigmoid(y2,wo2)\n","\n","y = pred(y)\n","\n","# performance measures\n","ind_accuracy, accuracy = performance(y_test, y)\n","print(\"accuracy of class 1 = {}\".format(ind_accuracy[0]))\n","print(\"accuracy of class 2 = {}\".format(ind_accuracy[1]))\n","print(\"accuracy of class 3 = {}\".format(ind_accuracy[2]))\n","print(\"overall accuracy of classifier = {}\".format(accuracy))"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["accuracy of class 1 = 1.0\n","accuracy of class 2 = 1.0\n","accuracy of class 3 = 0.8947368421052632\n","overall accuracy of classifier = 0.9523809523809523\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"LYqeghjNO1uX","executionInfo":{"status":"ok","timestamp":1637310272180,"user_tz":-330,"elapsed":466,"user":{"displayName":"Abhay Patwari","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gix32BX_ssvRlYOdFlU8riZsgPg3lrL-_h0Lvui=s64","userId":"16538957145694214892"}},"outputId":"3bfbceeb-f791-4945-aa20-113af127f9a9"},"source":["# using 5-fold cross validation\n","x_subsets, y_subsets = five_fold(data)\n","\n","T = 200\n","alpha = 0.1\n","ni = np.shape(x_train)[1] # number of input neurons (features)\n","no = 3 # number of ouput neurons (classes)\n","nh1 = 6 # number of neurons in first hidden layer\n","nh2 = 8 # number of neurons in second hidden layer\n","\n","accuracy_vals = [] # accuracy from all folds\n","ind_accuracy1 = [] # class1 accuracy from all folds\n","ind_accuracy2 = [] # class2 accuracy from all folds\n","ind_accuracy3 = [] # class3 accuracy from all folds\n","\n","# 5 fold CV\n","for fold in range(5):\n","  # test-train split\n","  x_test = x_subsets[fold]\n","  y_test = y_subsets[fold]\n","\n","  x_train = np.concatenate(np.delete(x_subsets, fold, 0), axis=0)\n","  y_train = np.concatenate(np.delete(y_subsets, fold, 0), axis=0)\n","\n","  # normalizing input data\n","  mu = np.mean(x_train, axis=0)\n","  std = np.std(x_train, axis=0)\n","\n","  x_train = (x_train-mu)/std\n","  x_test = (x_test-mu)/std\n","\n","  # one-hot-encoding output data\n","  y_train_coded = one_hot_encode(y_train)\n","  y_test_coded = one_hot_encode(y_test)\n","\n","  # appending ones (input for bias)\n","  x_train = appendones(x_train)\n","  x_test = appendones(x_test)\n","\n","  # random weights\n","  np.random.seed(0)\n","  w1i = np.random.randn(nh1, ni)\n","  np.random.seed(0)\n","  w21 = np.random.randn(nh2, nh1)\n","  np.random.seed(0)\n","  wo2 = np.random.randn(no, nh2)\n","\n","  # training\n","  for i in range(T):\n","\n","    # forward path propagation\n","    y1 = sigmoid(x_train,w1i)\n","    y2 = sigmoid(y1,w21)\n","    y =  sigmoid(y2,wo2)\n","\n","    # back propagation\n","    \n","    \"\"\"updating output layer weights\"\"\"\n","    delta = (y_train_coded - y) * y * (1 - y)\n","    wo2 = wo2 + alpha * np.dot(delta.T, y2)\n","\n","    \"\"\"updating 2nd hidden layer weights\"\"\"\n","    delta = y2*(1-y2) * np.dot(delta,wo2)\n","    w21 = w21 + alpha * np.dot(delta.T, y1)\n","\n","    \"\"\"updating 1st hidden layer weights\"\"\"\n","    delta = y1*(1-y1) * np.dot(delta,w21)\n","    w1i = w1i + alpha * np.dot(delta.T, x_train)\n","\n","  # testing\n","  y1 = sigmoid(x_test,w1i)\n","  y2 = sigmoid(y1,w21)\n","  y =  sigmoid(y2,wo2)\n","\n","  y = pred(y)\n","\n","  # performance measures\n","  ind_accuracy, accuracy = performance(y_test, y)\n","  accuracy_vals.append(accuracy)\n","  ind_accuracy1.append(ind_accuracy[0])\n","  ind_accuracy2.append(ind_accuracy[1])\n","  ind_accuracy3.append(ind_accuracy[2])\n","\n","\n","print(\"mean accuracy of class 1 = {}\".format(np.mean(ind_accuracy1)))\n","print(\"mean accuracy of class 2 = {}\".format(np.mean(ind_accuracy2)))\n","print(\"mean accuracy of class 3 = {}\".format(np.mean(ind_accuracy3)))\n","print(\"overall accuracy of classifier = {}\".format(np.mean(accuracy_vals)))"],"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["mean accuracy of class 1 = 0.9453781512605042\n","mean accuracy of class 2 = 0.9625\n","mean accuracy of class 3 = 0.9356140350877192\n","overall accuracy of classifier = 0.9428571428571428\n"]}]}]}