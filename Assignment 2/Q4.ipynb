{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Q4.ipynb","provenance":[],"collapsed_sections":[],"mount_file_id":"1N8p15U6E_PlUDf61nnBqdSyzSJwM0WdV","authorship_tag":"ABX9TyNXHLKHaXVreWADyY5VwI9A"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","metadata":{"id":"-jUu4vgsuMmb","executionInfo":{"status":"ok","timestamp":1637314992348,"user_tz":-330,"elapsed":502,"user":{"displayName":"Abhay Patwari","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gix32BX_ssvRlYOdFlU8riZsgPg3lrL-_h0Lvui=s64","userId":"16538957145694214892"}}},"source":["import numpy as np\n","import pandas as pd\n","\n","def rbf_kernel(x1, x2, sigma):\n","  return np.exp(-np.linalg.norm(x1-x2)**2 / (2 * sigma**2))\n","\n","def linear_kernel(x1, x2):\n","  return np.dot(x1, x2)\n","\n","def multiquadric_kernel(x1, x2, sigma):\n","  return np.sqrt(np.linalg.norm(x1-x2)**2 + sigma**2)\n","\n","def kmeans_clustering(data, k, iters):\n","  rng = np.random.default_rng(seed=0)\n","  m = data.shape[0]\n","  label = rng.choice(range(k), m) # initial random labels\n","  kmeans = np.zeros((k,data.shape[1])) # mean matrix, jth row is mean vector for jth cluster\n","  kstd = np.zeros((k,data.shape[1]))\n","  for iter in range(iters):\n","    for cluster in range(k):\n","      cluster_points = data[label==cluster]\n","      if cluster_points.size==0:\n","        continue\n","      kmeans[cluster] = np.mean(cluster_points, axis=0)\n","      kstd[cluster] = np.std(cluster_points, axis=0)\n","    \n","    # updating labels\n","    for i in range(m):\n","      distances = []\n","      for j in range(k):\n","        diff = data[i] - kmeans[j]\n","        dist = np.sum(np.square(diff))\n","        distances.append(dist)\n","      label[i] = np.argmin(distances)\n","  return kmeans,np.mean(kstd)\n","\n","def holdout(data, trainp, validp):\n","  m = np.shape(data)[0]\n","\n","  train = data[0 : int(np.floor(m*trainp/100))]\n","  valid = data[int(np.floor(m*trainp/100)) : int(np.floor(m*trainp/100))+int(np.floor(m*validp/100))]\n","  test = data[int(np.floor(m*trainp/100))+int(np.floor(m*validp/100)) : None]\n","\n","  y_train = train[:,-1] #shape = (rows,)\n","  x_train = np.delete(train, -1, axis=1)\n","\n","  y_valid = valid[:,-1] #shape = (rows,)\n","  x_valid = np.delete(valid, -1, axis=1)\n","\n","  y_test = test[:,-1] #shape = (rows,)\n","  x_test = np.delete(test, -1, axis=1)\n","\n","  return x_train,x_valid,x_test,y_train,y_valid,y_test\n","\n","def five_fold(data):\n","  y = data[:,-1]\n","  x = np.delete(data, -1, axis=1)\n","  x_subsets = np.array_split(x, 5)\n","  y_subsets = np.array_split(y, 5)\n","  return x_subsets,y_subsets\n","\n","def appendones(x):\n","  m = np.shape(x)[0]\n","  return np.concatenate((np.ones((m,1)),x), axis=1)\n","\n","def one_hot_encode(y):\n","  len = np.size(y)\n","  encoded_y = np.zeros((len,3))\n","  for i in range(len):\n","    if y[i] == 1:\n","      encoded_y[i,0] = 1\n","    if y[i] == 2:\n","      encoded_y[i,1] = 1\n","    if y[i] == 3:\n","      encoded_y[i,2] = 1\n","  return encoded_y\n","\n","def performance(y, pred):\n","  m = np.zeros((3,3)) # confusion matrix\n","  for p in range(len(pred)):\n","    if pred[p]==1 and y[p]==1:\n","      m[0,0]+=1\n","    if pred[p]==2 and y[p]==2:\n","      m[1,1]+=1\n","    if pred[p]==3 and y[p]==3:\n","      m[2,2]+=1\n","    if pred[p]==1 and y[p]==2:\n","      m[1,0]+=1\n","    if pred[p]==1 and y[p]==3:\n","      m[2,0]+=1\n","    if pred[p]==2 and y[p]==1:\n","      m[0,1]+=1\n","    if pred[p]==2 and y[p]==3:\n","      m[2,1]+=1\n","    if pred[p]==3 and y[p]==1:\n","      m[0,2]+=1\n","    if pred[p]==3 and y[p]==2:\n","      m[1,2]+=1\n","  ind_accuracy = [m[0,0]/np.sum(m[0,:]), m[1,1]/np.sum(m[1,:]), m[2,2]/np.sum(m[2,:])]\n","  accuracy = (m[0,0]+m[1,1]+m[2,2])/np.sum(m)\n","  return ind_accuracy, accuracy\n","\n","def pred(y):\n","  return (np.argmax(y, axis=1) + 1)"],"execution_count":34,"outputs":[]},{"cell_type":"code","metadata":{"id":"BRgZYxm9Khs5","executionInfo":{"status":"ok","timestamp":1637315011223,"user_tz":-330,"elapsed":723,"user":{"displayName":"Abhay Patwari","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gix32BX_ssvRlYOdFlU8riZsgPg3lrL-_h0Lvui=s64","userId":"16538957145694214892"}}},"source":["data = pd.read_excel('/content/drive/MyDrive/NNFL Assignments (Aug 2021)/Assignment 2/data5.xlsx')\n","cols = np.array(data.columns, ndmin=2)\n","data = data.to_numpy()\n","data = np.concatenate((cols,data), axis=0)\n","\n","# shuffle & train-test-valid-split\n","np.random.seed(0)\n","np.random.shuffle(data)\n","x_train, x_valid, x_test, y_train, y_valid, y_test = holdout(data, 70, 10)\n","\n","# normalizing input data\n","mu = np.mean(x_train, axis=0)\n","std = np.std(x_train, axis=0)\n","\n","x_train = (x_train-mu)/std\n","x_valid = (x_valid-mu)/std\n","x_test = (x_test-mu)/std\n","\n","# one-hot-encoding output data\n","y_train_coded = one_hot_encode(y_train)\n","y_valid_coded = one_hot_encode(y_valid)\n","y_test_coded = one_hot_encode(y_test)\n","\n","# appending ones (input for bias)\n","x_train = appendones(x_train)\n","x_valid = appendones(x_valid)\n","x_test = appendones(x_test)\n","\n","m_train = np.size(y_train)\n","m_valid = np.size(y_valid)\n","m_test = np.size(y_test)"],"execution_count":35,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Q7Jnp8gx-tYb"},"source":["Using Gaussian Kernel"]},{"cell_type":"code","metadata":{"id":"WQnV-cl5zyVA","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1637314102493,"user_tz":-330,"elapsed":4567,"user":{"displayName":"Abhay Patwari","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gix32BX_ssvRlYOdFlU8riZsgPg3lrL-_h0Lvui=s64","userId":"16538957145694214892"}},"outputId":"e2408724-3363-4327-b7e7-85341386a72c"},"source":["# parameters\n","k = 12\n","mu, sigma = kmeans_clustering(x_train, k, 200)\n","\n","# training\n","y1 = np.zeros((m_train,k))\n","for i in range(m_train):\n","  y1[i] = np.array([rbf_kernel(x_train[i], mu[j], sigma) for j in range(k)])\n","\n","w = np.linalg.pinv(y1) @ y_train_coded\n","\n","# testing\n","y_11 = np.zeros((m_test,k))\n","for i in range(m_test):\n","  y_11[i] = np.array([rbf_kernel(x_test[i], mu[j], sigma) for j in range(k)])\n","\n","y = y_11 @ w\n","y = pred(y)\n","\n","# performance measures\n","ind_accuracy, accuracy = performance(y_test, y)\n","print(\"accuracy of class 1 = {}\".format(ind_accuracy[0]))\n","print(\"accuracy of class 2 = {}\".format(ind_accuracy[1]))\n","print(\"accuracy of class 3 = {}\".format(ind_accuracy[2]))\n","print(\"overall accuracy of classifier = {}\".format(accuracy))"],"execution_count":32,"outputs":[{"output_type":"stream","name":"stdout","text":["accuracy of class 1 = 0.9\n","accuracy of class 2 = 1.0\n","accuracy of class 3 = 0.8421052631578947\n","overall accuracy of classifier = 0.9047619047619048\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"GukwrAjdipJm","executionInfo":{"status":"ok","timestamp":1637315040083,"user_tz":-330,"elapsed":21444,"user":{"displayName":"Abhay Patwari","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gix32BX_ssvRlYOdFlU8riZsgPg3lrL-_h0Lvui=s64","userId":"16538957145694214892"}},"outputId":"fe7de55c-13fa-4288-f818-135edbff6128"},"source":["# using 5-fold crossvalidation\n","x_subsets, y_subsets = five_fold(data)\n","\n","accuracy_vals = [] # accuracy from all folds\n","ind_accuracy1 = [] # class1 accuracy from all folds\n","ind_accuracy2 = [] # class2 accuracy from all folds\n","ind_accuracy3 = [] # class3 accuracy from all folds\n","\n","# 5 fold CV\n","for fold in range(5):\n","  # test-train split\n","  x_test = x_subsets[fold]\n","  y_test = y_subsets[fold]\n","\n","  x_train = np.concatenate(np.delete(x_subsets, fold, 0), axis=0)\n","  y_train = np.concatenate(np.delete(y_subsets, fold, 0), axis=0)\n","\n","  # normalizing input data\n","  mu = np.mean(x_train, axis=0)\n","  std = np.std(x_train, axis=0)\n","\n","  x_train = (x_train-mu)/std\n","  x_test = (x_test-mu)/std\n","\n","  # one-hot-encoding output data\n","  y_train_coded = one_hot_encode(y_train)\n","  y_test_coded = one_hot_encode(y_test)\n","\n","  # appending ones (input for bias)\n","  x_train = appendones(x_train)\n","  x_test = appendones(x_test)\n","\n","  m_train = np.size(y_train)\n","  m_test = np.size(y_test)\n","\n","  # parameters\n","  k = 12\n","  mu, sigma = kmeans_clustering(x_train, k, 200)\n","\n","  # training\n","  y1 = np.zeros((m_train,k))\n","  for i in range(m_train):\n","    y1[i] = np.array([rbf_kernel(x_train[i], mu[j], sigma) for j in range(k)])\n","\n","  w = np.linalg.pinv(y1) @ y_train_coded\n","\n","  # testing\n","  y_11 = np.zeros((m_test,k))\n","  for i in range(m_test):\n","    y_11[i] = np.array([rbf_kernel(x_test[i], mu[j], sigma) for j in range(k)])\n","\n","  y = y_11 @ w\n","  y = pred(y)\n","\n","  # performance measures\n","  ind_accuracy, accuracy = performance(y_test, y)\n","  accuracy_vals.append(accuracy)\n","  ind_accuracy1.append(ind_accuracy[0])\n","  ind_accuracy2.append(ind_accuracy[1])\n","  ind_accuracy3.append(ind_accuracy[2])\n","\n","print(\"mean accuracy of class 1 = {}\".format(ind_accuracy[0]))\n","print(\"mean accuracy of class 2 = {}\".format(ind_accuracy[1]))\n","print(\"mean accuracy of class 3 = {}\".format(ind_accuracy[2]))\n","print(\"mean overall accuracy of classifier = {}\".format(accuracy))"],"execution_count":36,"outputs":[{"output_type":"stream","name":"stdout","text":["mean accuracy of class 1 = 0.7\n","mean accuracy of class 2 = 1.0\n","mean accuracy of class 3 = 0.8421052631578947\n","mean overall accuracy of classifier = 0.8571428571428571\n"]}]},{"cell_type":"markdown","metadata":{"id":"edjBMoYl_OD-"},"source":["Using Multiquadric Kernel"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"QAnzXubobU1t","executionInfo":{"status":"ok","timestamp":1637314011374,"user_tz":-330,"elapsed":3864,"user":{"displayName":"Abhay Patwari","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gix32BX_ssvRlYOdFlU8riZsgPg3lrL-_h0Lvui=s64","userId":"16538957145694214892"}},"outputId":"e50f0107-c8a3-4d91-a3e9-61ea6a2b26c3"},"source":["# parameters\n","k = 12\n","mu, sigma = kmeans_clustering(x_train, k, 200)\n","\n","# training\n","y1 = np.zeros((m_train,k))\n","for i in range(m_train):\n","  y1[i] = np.array([multiquadric_kernel(x_train[i], mu[j], sigma) for j in range(k)])\n","\n","w = np.linalg.pinv(y1) @ y_train_coded\n","\n","# testing\n","y_11 = np.zeros((m_test,k))\n","for i in range(m_test):\n","  y_11[i] = np.array([multiquadric_kernel(x_test[i], mu[j], sigma) for j in range(k)])\n","\n","y = y_11 @ w\n","y = pred(y)\n","\n","# performance measures\n","ind_accuracy, accuracy = performance(y_test, y)\n","print(\"accuracy of class 1 = {}\".format(ind_accuracy[0]))\n","print(\"accuracy of class 2 = {}\".format(ind_accuracy[1]))\n","print(\"accuracy of class 3 = {}\".format(ind_accuracy[2]))\n","print(\"overall accuracy of classifier = {}\".format(accuracy))"],"execution_count":30,"outputs":[{"output_type":"stream","name":"stdout","text":["accuracy of class 1 = 1.0\n","accuracy of class 2 = 1.0\n","accuracy of class 3 = 0.7894736842105263\n","overall accuracy of classifier = 0.9047619047619048\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ZlhDLIlxlS-H","executionInfo":{"status":"ok","timestamp":1637315119332,"user_tz":-330,"elapsed":21210,"user":{"displayName":"Abhay Patwari","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gix32BX_ssvRlYOdFlU8riZsgPg3lrL-_h0Lvui=s64","userId":"16538957145694214892"}},"outputId":"f3b8451c-fdc2-462b-aaa8-b3ab12a07f39"},"source":["# using 5-fold crossvalidation\n","x_subsets, y_subsets = five_fold(data)\n","\n","accuracy_vals = [] # accuracy from all folds\n","ind_accuracy1 = [] # class1 accuracy from all folds\n","ind_accuracy2 = [] # class2 accuracy from all folds\n","ind_accuracy3 = [] # class3 accuracy from all folds\n","\n","# 5 fold CV\n","for fold in range(5):\n","  # test-train split\n","  x_test = x_subsets[fold]\n","  y_test = y_subsets[fold]\n","\n","  x_train = np.concatenate(np.delete(x_subsets, fold, 0), axis=0)\n","  y_train = np.concatenate(np.delete(y_subsets, fold, 0), axis=0)\n","\n","  # normalizing input data\n","  mu = np.mean(x_train, axis=0)\n","  std = np.std(x_train, axis=0)\n","\n","  x_train = (x_train-mu)/std\n","  x_test = (x_test-mu)/std\n","\n","  # one-hot-encoding output data\n","  y_train_coded = one_hot_encode(y_train)\n","  y_test_coded = one_hot_encode(y_test)\n","\n","  # appending ones (input for bias)\n","  x_train = appendones(x_train)\n","  x_test = appendones(x_test)\n","\n","  m_train = np.size(y_train)\n","  m_test = np.size(y_test)\n","\n","  # parameters\n","  k = 12\n","  mu, sigma = kmeans_clustering(x_train, k, 200)\n","\n","  # training\n","  y1 = np.zeros((m_train,k))\n","  for i in range(m_train):\n","    y1[i] = np.array([multiquadric_kernel(x_train[i], mu[j], sigma) for j in range(k)])\n","\n","  w = np.linalg.pinv(y1) @ y_train_coded\n","\n","  # testing\n","  y_11 = np.zeros((m_test,k))\n","  for i in range(m_test):\n","    y_11[i] = np.array([multiquadric_kernel(x_test[i], mu[j], sigma) for j in range(k)])\n","\n","  y = y_11 @ w\n","  y = pred(y)\n","\n","  # performance measures\n","  ind_accuracy, accuracy = performance(y_test, y)\n","  accuracy_vals.append(accuracy)\n","  ind_accuracy1.append(ind_accuracy[0])\n","  ind_accuracy2.append(ind_accuracy[1])\n","  ind_accuracy3.append(ind_accuracy[2])\n","\n","print(\"mean accuracy of class 1 = {}\".format(ind_accuracy[0]))\n","print(\"mean accuracy of class 2 = {}\".format(ind_accuracy[1]))\n","print(\"mean accuracy of class 3 = {}\".format(ind_accuracy[2]))\n","print(\"mean overall accuracy of classifier = {}\".format(accuracy))"],"execution_count":37,"outputs":[{"output_type":"stream","name":"stdout","text":["mean accuracy of class 1 = 1.0\n","mean accuracy of class 2 = 1.0\n","mean accuracy of class 3 = 0.8421052631578947\n","mean overall accuracy of classifier = 0.9285714285714286\n"]}]},{"cell_type":"markdown","metadata":{"id":"16zvpVzE_cEG"},"source":["Using Linear Kernel"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"C7kFAHI4hTZ4","executionInfo":{"status":"ok","timestamp":1637314087349,"user_tz":-330,"elapsed":3923,"user":{"displayName":"Abhay Patwari","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gix32BX_ssvRlYOdFlU8riZsgPg3lrL-_h0Lvui=s64","userId":"16538957145694214892"}},"outputId":"817b277e-8159-4080-9e67-135419cc0752"},"source":["# parameters\n","k = 12\n","mu, sigma = kmeans_clustering(x_train, k, 200)\n","\n","# training\n","y1 = np.zeros((m_train,k))\n","for i in range(m_train):\n","  y1[i] = np.array([linear_kernel(x_train[i], mu[j]) for j in range(k)])\n","\n","w = np.linalg.pinv(y1) @ y_train_coded\n","\n","# testing\n","y_11 = np.zeros((m_test,k))\n","for i in range(m_test):\n","  y_11[i] = np.array([linear_kernel(x_test[i], mu[j]) for j in range(k)])\n","\n","y = y_11 @ w\n","y = pred(y)\n","\n","# performance measures\n","ind_accuracy, accuracy = performance(y_test, y)\n","print(\"accuracy of class 1 = {}\".format(ind_accuracy[0]))\n","print(\"accuracy of class 2 = {}\".format(ind_accuracy[1]))\n","print(\"accuracy of class 3 = {}\".format(ind_accuracy[2]))\n","print(\"overall accuracy of classifier = {}\".format(accuracy))"],"execution_count":31,"outputs":[{"output_type":"stream","name":"stdout","text":["accuracy of class 1 = 0.9\n","accuracy of class 2 = 1.0\n","accuracy of class 3 = 0.8947368421052632\n","overall accuracy of classifier = 0.9285714285714286\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"cHB-_-sglcjg","executionInfo":{"status":"ok","timestamp":1637315166456,"user_tz":-330,"elapsed":21249,"user":{"displayName":"Abhay Patwari","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gix32BX_ssvRlYOdFlU8riZsgPg3lrL-_h0Lvui=s64","userId":"16538957145694214892"}},"outputId":"718911f9-be8d-4daf-ee00-a304d2978e60"},"source":["# using 5-fold crossvalidation\n","x_subsets, y_subsets = five_fold(data)\n","\n","accuracy_vals = [] # accuracy from all folds\n","ind_accuracy1 = [] # class1 accuracy from all folds\n","ind_accuracy2 = [] # class2 accuracy from all folds\n","ind_accuracy3 = [] # class3 accuracy from all folds\n","\n","# 5 fold CV\n","for fold in range(5):\n","  # test-train split\n","  x_test = x_subsets[fold]\n","  y_test = y_subsets[fold]\n","\n","  x_train = np.concatenate(np.delete(x_subsets, fold, 0), axis=0)\n","  y_train = np.concatenate(np.delete(y_subsets, fold, 0), axis=0)\n","\n","  # normalizing input data\n","  mu = np.mean(x_train, axis=0)\n","  std = np.std(x_train, axis=0)\n","\n","  x_train = (x_train-mu)/std\n","  x_test = (x_test-mu)/std\n","\n","  # one-hot-encoding output data\n","  y_train_coded = one_hot_encode(y_train)\n","  y_test_coded = one_hot_encode(y_test)\n","\n","  # appending ones (input for bias)\n","  x_train = appendones(x_train)\n","  x_test = appendones(x_test)\n","\n","  m_train = np.size(y_train)\n","  m_test = np.size(y_test)\n","\n","  # parameters\n","  k = 12\n","  mu, sigma = kmeans_clustering(x_train, k, 200)\n","\n","  # training\n","  y1 = np.zeros((m_train,k))\n","  for i in range(m_train):\n","    y1[i] = np.array([linear_kernel(x_train[i], mu[j]) for j in range(k)])\n","\n","  w = np.linalg.pinv(y1) @ y_train_coded\n","\n","  # testing\n","  y_11 = np.zeros((m_test,k))\n","  for i in range(m_test):\n","    y_11[i] = np.array([linear_kernel(x_test[i], mu[j]) for j in range(k)])\n","\n","  y = y_11 @ w\n","  y = pred(y)\n","\n","  # performance measures\n","  ind_accuracy, accuracy = performance(y_test, y)\n","  accuracy_vals.append(accuracy)\n","  ind_accuracy1.append(ind_accuracy[0])\n","  ind_accuracy2.append(ind_accuracy[1])\n","  ind_accuracy3.append(ind_accuracy[2])\n","\n","print(\"mean accuracy of class 1 = {}\".format(ind_accuracy[0]))\n","print(\"mean accuracy of class 2 = {}\".format(ind_accuracy[1]))\n","print(\"mean accuracy of class 3 = {}\".format(ind_accuracy[2]))\n","print(\"mean overall accuracy of classifier = {}\".format(accuracy))"],"execution_count":38,"outputs":[{"output_type":"stream","name":"stdout","text":["mean accuracy of class 1 = 1.0\n","mean accuracy of class 2 = 1.0\n","mean accuracy of class 3 = 0.8947368421052632\n","mean overall accuracy of classifier = 0.9523809523809523\n"]}]}]}