{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Q6.ipynb","provenance":[],"collapsed_sections":[],"mount_file_id":"1C37ooJ5yJ_zczHrE-xo9jcyu1jMA_do5","authorship_tag":"ABX9TyNfe+RY04cREyPDItQSScJz"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","metadata":{"id":"iJJigW3DPYDp","executionInfo":{"status":"ok","timestamp":1637908922974,"user_tz":-330,"elapsed":734,"user":{"displayName":"Abhay Patwari","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gix32BX_ssvRlYOdFlU8riZsgPg3lrL-_h0Lvui=s64","userId":"16538957145694214892"}}},"source":["import numpy as np\n","import pandas as pd\n","\n","def gaussian(v,x):\n","  m = np.shape(x)[0]\n","  L = np.shape(v)[0]\n","  final_out = np.zeros((m,L))\n","  for i in range(m):\n","    for j in range(L):\n","      norm_arg = x[i,1:] - v[j,1:]\n","      norm = np.linalg.norm(norm_arg)\n","      bias_term = -1*v[j,0]\n","      final_out[i,j] = np.exp(bias_term*norm)\n","  return final_out\n","\n","def five_fold(data):\n","  y = data[:,-1]\n","  x = np.delete(data, -1, axis=1)\n","  x_subsets = np.array_split(x, 5)\n","  y_subsets = np.array_split(y, 5)\n","  return x_subsets,y_subsets\n","\n","def appendones(x):\n","  m = np.shape(x)[0]\n","  return np.concatenate((np.ones((m,1)),x), axis=1)\n","\n","def one_hot_encode(y):\n","  len = np.size(y)\n","  encoded_y = np.zeros((len,3))\n","  for i in range(len):\n","    if y[i] == 1:\n","      encoded_y[i,0] = 1\n","    if y[i] == 2:\n","      encoded_y[i,1] = 1\n","    if y[i] == 3:\n","      encoded_y[i,2] = 1\n","  return encoded_y\n","\n","def decode(y):\n","  len = np.shape(y)[0]\n","  class_labels = np.zeros(len)\n","  for i in range(len):\n","    class_labels[i] = np.argmax(y[i])+1\n","  return class_labels\n","\n","def performance(y, pred):\n","  m = np.zeros((3,3)) # confusion matrix\n","  for p in range(len(pred)):\n","    if pred[p]==1 and y[p]==1:\n","      m[0,0]+=1\n","    if pred[p]==2 and y[p]==2:\n","      m[1,1]+=1\n","    if pred[p]==3 and y[p]==3:\n","      m[2,2]+=1\n","    if pred[p]==1 and y[p]==2:\n","      m[1,0]+=1\n","    if pred[p]==1 and y[p]==3:\n","      m[2,0]+=1\n","    if pred[p]==2 and y[p]==1:\n","      m[0,1]+=1\n","    if pred[p]==2 and y[p]==3:\n","      m[2,1]+=1\n","    if pred[p]==3 and y[p]==1:\n","      m[0,2]+=1\n","    if pred[p]==3 and y[p]==2:\n","      m[1,2]+=1\n","  ind_accuracy = [m[0,0]/np.sum(m[0,:]), m[1,1]/np.sum(m[1,:]), m[2,2]/np.sum(m[2,:])]\n","  accuracy = (m[0,0]+m[1,1]+m[2,2])/np.sum(m)\n","  return ind_accuracy, accuracy"],"execution_count":1,"outputs":[]},{"cell_type":"code","metadata":{"id":"ELUrK9cLZADj","executionInfo":{"status":"ok","timestamp":1637908924248,"user_tz":-330,"elapsed":1283,"user":{"displayName":"Abhay Patwari","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gix32BX_ssvRlYOdFlU8riZsgPg3lrL-_h0Lvui=s64","userId":"16538957145694214892"}}},"source":["data = pd.read_excel('/content/drive/MyDrive/NNFL Assignments (Aug 2021)/Assignment 2/data5.xlsx')\n","cols = np.array(data.columns, ndmin=2)\n","data = data.to_numpy()\n","data = np.concatenate((cols,data), axis=0)\n","\n","# shuffle\n","np.random.seed(0)\n","np.random.shuffle(data)"],"execution_count":2,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jWb853dAZOM-","executionInfo":{"status":"ok","timestamp":1637908924250,"user_tz":-330,"elapsed":19,"user":{"displayName":"Abhay Patwari","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gix32BX_ssvRlYOdFlU8riZsgPg3lrL-_h0Lvui=s64","userId":"16538957145694214892"}},"outputId":"e38232b8-b232-43b6-c95e-49165ca49c74"},"source":["# using tan hyperbolic activation\n","x_subsets, y_subsets = five_fold(data)\n","\n","ni = 8 # input layer\n","L = 15 # number of hidden ELM units\n","no = 3 # output layer\n","\n","accuracy_vals = [] # accuracy from all folds\n","ind_accuracy1 = [] # class1 accuracy from all folds\n","ind_accuracy2 = [] # class2 accuracy from all folds\n","ind_accuracy3 = [] # class3 accuracy from all folds\n","\n","# 5 fold CV\n","for fold in range(5):\n","  # test-train split\n","  x_test = x_subsets[fold]\n","  y_test = y_subsets[fold]\n","\n","  x_train = np.concatenate(np.delete(x_subsets, fold, 0), axis=0)\n","  y_train = np.concatenate(np.delete(y_subsets, fold, 0), axis=0)\n","\n","  # normalizing input data\n","  mu = np.mean(x_train, axis=0)\n","  std = np.std(x_train, axis=0)\n","\n","  x_train = (x_train-mu)/std\n","  x_test = (x_test-mu)/std\n","\n","  # one-hot-encoding output data\n","  y_train_coded = one_hot_encode(y_train)\n","  y_test_coded = one_hot_encode(y_test)\n","\n","  # appending ones (input for bias)\n","  x_train = appendones(x_train)\n","  x_test = appendones(x_test)\n","\n","  ###### TRAINING ######\n","  # random input-to-hidden layer weights\n","  np.random.seed(0)\n","  v = np.random.randn(L, ni)\n","  \n","  # hidden layer output (tan hyperbolic activation)\n","  H = np.tanh(x_train @ v.T)\n","\n","  # hidden-to-output layer weights\n","  w = np.linalg.pinv(H) @ y_train_coded\n","\n","  ###### TESTING ######\n","  H = np.tanh(x_test @ v.T)\n","  y = H @ w\n","  pred = decode(y)\n","\n","  # performance measures\n","  ind_accuracy, accuracy = performance(y_test, pred)\n","  accuracy_vals.append(accuracy)\n","  ind_accuracy1.append(ind_accuracy[0])\n","  ind_accuracy2.append(ind_accuracy[1])\n","  ind_accuracy3.append(ind_accuracy[2])\n","\n","print(\"mean accuracy of class 1 = {}\".format(ind_accuracy[0]))\n","print(\"mean accuracy of class 2 = {}\".format(ind_accuracy[1]))\n","print(\"mean accuracy of class 3 = {}\".format(ind_accuracy[2]))\n","print(\"mean overall accuracy of classifier = {}\".format(accuracy))"],"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["mean accuracy of class 1 = 0.8\n","mean accuracy of class 2 = 1.0\n","mean accuracy of class 3 = 0.8947368421052632\n","mean overall accuracy of classifier = 0.9047619047619048\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Um1XY9dAKAIB","executionInfo":{"status":"ok","timestamp":1637908925141,"user_tz":-330,"elapsed":900,"user":{"displayName":"Abhay Patwari","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gix32BX_ssvRlYOdFlU8riZsgPg3lrL-_h0Lvui=s64","userId":"16538957145694214892"}},"outputId":"0608483a-d052-4ca7-942b-42e42fc32d12"},"source":["# using gaussian activation\n","x_subsets, y_subsets = five_fold(data)\n","\n","ni = 8 # input layer\n","L = 31 # number of hidden ELM units\n","no = 3 # output layer\n","\n","accuracy_vals = [] # accuracy from all folds\n","ind_accuracy1 = [] # class1 accuracy from all folds\n","ind_accuracy2 = [] # class2 accuracy from all folds\n","ind_accuracy3 = [] # class3 accuracy from all folds\n","\n","# 5 fold CV\n","for fold in range(5):\n","  # test-train split\n","  x_test = x_subsets[fold]\n","  y_test = y_subsets[fold]\n","\n","  x_train = np.concatenate(np.delete(x_subsets, fold, 0), axis=0)\n","  y_train = np.concatenate(np.delete(y_subsets, fold, 0), axis=0)\n","\n","  # normalizing input data\n","  mu = np.mean(x_train, axis=0)\n","  std = np.std(x_train, axis=0)\n","\n","  x_train = (x_train-mu)/std\n","  x_test = (x_test-mu)/std\n","\n","  # one-hot-encoding output data\n","  y_train_coded = one_hot_encode(y_train)\n","  y_test_coded = one_hot_encode(y_test)\n","\n","  # appending ones (input for bias)\n","  x_train = appendones(x_train)\n","  x_test = appendones(x_test)\n","\n","  # TRAINING\n","  # random input-to-hidden layer weights\n","  np.random.seed(0)\n","  v = np.random.randn(L, ni)\n","\n","  # hidden layer output (gaussian activation)\n","  H = gaussian(v,x_train)\n","\n","  # hidden-to-output layer weights\n","  w = np.linalg.pinv(H) @ y_train_coded\n","\n","  # TESTING\n","  H = gaussian(v, x_test)\n","  y = H @ w\n","  pred = decode(y)\n","\n","  # performance measures\n","  ind_accuracy, accuracy = performance(y_test, pred)\n","  accuracy_vals.append(accuracy)\n","  ind_accuracy1.append(ind_accuracy[0])\n","  ind_accuracy2.append(ind_accuracy[1])\n","  ind_accuracy3.append(ind_accuracy[2])\n","\n","print(\"mean accuracy of class 1 = {}\".format(ind_accuracy[0]))\n","print(\"mean accuracy of class 2 = {}\".format(ind_accuracy[1]))\n","print(\"mean accuracy of class 3 = {}\".format(ind_accuracy[2]))\n","print(\"mean overall accuracy of classifier = {}\".format(accuracy))"],"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["mean accuracy of class 1 = 0.9\n","mean accuracy of class 2 = 0.9230769230769231\n","mean accuracy of class 3 = 0.9473684210526315\n","mean overall accuracy of classifier = 0.9285714285714286\n"]}]}]}